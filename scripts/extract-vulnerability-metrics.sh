#!/bin/bash

# extract-vulnerability-metrics.sh
# Extracts metrics from vulnerability scanning structured logs and ships to observability platforms
#
# Usage: extract-vulnerability-metrics.sh [log_file]
#
# Environment Variables:
#   OBSERVABILITY_PLATFORM - Target platform (prometheus|datadog|cloudwatch) [default: prometheus]
#   OBSERVABILITY_ENDPOINT - Platform endpoint URL
#   OBSERVABILITY_AUTH_TOKEN - Authentication token (for platforms requiring it)
#   METRICS_ENABLED - Enable/disable metrics extraction [default: true]
#   METRICS_DRY_RUN - Only parse logs, don't ship metrics [default: false]
#   CI_ENVIRONMENT - Environment label for metrics [default: ci]
#   GITHUB_REPOSITORY - Repository name for metrics labeling

set -euo pipefail

# Configuration with defaults
OBSERVABILITY_PLATFORM="${OBSERVABILITY_PLATFORM:-prometheus}"
OBSERVABILITY_ENDPOINT="${OBSERVABILITY_ENDPOINT:-}"
OBSERVABILITY_AUTH_TOKEN="${OBSERVABILITY_AUTH_TOKEN:-}"
METRICS_ENABLED="${METRICS_ENABLED:-true}"
METRICS_DRY_RUN="${METRICS_DRY_RUN:-false}"
CI_ENVIRONMENT="${CI_ENVIRONMENT:-ci}"
GITHUB_REPOSITORY="${GITHUB_REPOSITORY:-unknown}"

# Script configuration
SCRIPT_DIR="$(dirname "${BASH_SOURCE[0]}")"
METRICS_FILE="/tmp/vulnerability-metrics.prom"
LOG_FILE="${1:-/dev/stdin}"

# Metrics accumulator
declare -A COUNTERS
declare -A GAUGES
declare -A HISTOGRAMS

# Logging function
log() {
    local level="$1"
    local message="$2"
    echo "[$(date -u '+%Y-%m-%dT%H:%M:%SZ')] [$level] [metrics-extractor] $message" >&2
}

# Parse structured log entry and extract metrics
parse_log_entry() {
    local log_line="$1"

    # Validate JSON format
    if ! echo "$log_line" | jq empty 2>/dev/null; then
        return 0  # Skip non-JSON lines
    fi

    # Extract fields using jq
    local service_name=$(echo "$log_line" | jq -r '.service_name // "unknown"')
    local level=$(echo "$log_line" | jq -r '.level // "unknown"')
    local correlation_id=$(echo "$log_line" | jq -r '.correlation_id // "unknown"')
    local scan_result=$(echo "$log_line" | jq -r '.scan_result // "unknown"')
    local scan_duration_ms=$(echo "$log_line" | jq -r '.scan_duration_ms // "null"')
    local timestamp=$(echo "$log_line" | jq -r '.timestamp // "unknown"')
    local git_commit=$(echo "$log_line" | jq -r '.git_commit // "unknown"')
    local message=$(echo "$log_line" | jq -r '.message // "unknown"')

    # Only process vulnerability scanner logs
    if [[ "$service_name" != "vulnerability-scanner" ]]; then
        return 0
    fi

    # Extract branch from git context or environment
    local branch="${GITHUB_REF_NAME:-unknown}"
    if [[ "$branch" == "unknown" ]]; then
        branch=$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo "unknown")
    fi

    # Common labels
    local base_labels="service=\"$service_name\",environment=\"$CI_ENVIRONMENT\",repository=\"$GITHUB_REPOSITORY\",branch=\"$branch\""

    # Extract metrics based on log content
    case "$level" in
        "INFO")
            if [[ "$scan_result" != "unknown" && "$scan_result" != "null" ]]; then
                # Scan completion metrics
                case "$scan_result" in
                    "clean")
                        increment_counter "vulnerability_scans_total" "$base_labels,status=\"success\",result=\"clean\""
                        ;;
                    "vulnerabilities_found")
                        increment_counter "vulnerability_scans_total" "$base_labels,status=\"success\",result=\"vulnerabilities_found\""

                        # Extract vulnerability counts
                        local vuln_counts=$(echo "$log_line" | jq -r '.vulnerability_counts // "{}"')
                        if [[ "$vuln_counts" != "{}" && "$vuln_counts" != "null" ]]; then
                            extract_vulnerability_counts "$vuln_counts" "$base_labels"
                        fi
                        ;;
                    "in_progress")
                        # Scan started - could track concurrent scans
                        increment_counter "vulnerability_scans_started_total" "$base_labels"
                        ;;
                esac

                # Extract scan duration
                if [[ "$scan_duration_ms" != "null" && "$scan_duration_ms" != "unknown" ]]; then
                    local duration_seconds=$(echo "scale=3; $scan_duration_ms / 1000" | bc)
                    record_histogram "vulnerability_scan_duration_seconds" "$duration_seconds" "$base_labels,status=\"success\",result=\"$scan_result\""
                fi
            fi
            ;;
        "ERROR")
            # Error metrics
            increment_counter "vulnerability_scans_total" "$base_labels,status=\"failure\",result=\"error\""

            # Classify error types
            local error_type="unknown"
            if [[ "$message" == *"timeout"* ]]; then
                error_type="timeout"
            elif [[ "$message" == *"network"* ]]; then
                error_type="network"
            elif [[ "$message" == *"configuration"* ]]; then
                error_type="configuration"
            elif [[ "$scan_result" == "build_terminated" ]]; then
                error_type="security_policy_violation"
            fi

            increment_counter "vulnerability_scan_errors_total" "$base_labels,error_type=\"$error_type\""

            # Extract scan duration for failed scans
            if [[ "$scan_duration_ms" != "null" && "$scan_duration_ms" != "unknown" ]]; then
                local duration_seconds=$(echo "scale=3; $scan_duration_ms / 1000" | bc)
                record_histogram "vulnerability_scan_duration_seconds" "$duration_seconds" "$base_labels,status=\"failure\",result=\"error\""
            fi
            ;;
        "WARN")
            # Warning metrics (like emergency overrides)
            if [[ "$message" == *"override"* ]]; then
                # Extract user from context or environment
                local override_user="${GITHUB_ACTOR:-unknown}"
                increment_counter "vulnerability_scan_overrides_total" "$base_labels,user=\"$override_user\""
            fi
            ;;
    esac
}

# Extract vulnerability counts from vulnerability_counts JSON
extract_vulnerability_counts() {
    local vuln_counts_json="$1"
    local base_labels="$2"

    # Parse vulnerability counts
    local critical_count=$(echo "$vuln_counts_json" | jq -r '.critical_count // 0')
    local high_count=$(echo "$vuln_counts_json" | jq -r '.high_count // 0')
    local medium_count=$(echo "$vuln_counts_json" | jq -r '.medium_count // 0')
    local low_count=$(echo "$vuln_counts_json" | jq -r '.low_count // 0')
    local total_count=$(echo "$vuln_counts_json" | jq -r '.total_vulnerabilities // 0')

    # Record current vulnerability counts
    set_gauge "vulnerability_count" "$critical_count" "$base_labels,severity=\"critical\""
    set_gauge "vulnerability_count" "$high_count" "$base_labels,severity=\"high\""
    set_gauge "vulnerability_count" "$medium_count" "$base_labels,severity=\"medium\""
    set_gauge "vulnerability_count" "$low_count" "$base_labels,severity=\"low\""

    # Record detection counters (cumulative)
    if [[ "$critical_count" -gt 0 ]]; then
        add_counter "vulnerabilities_detected_total" "$critical_count" "$base_labels,severity=\"critical\""
    fi
    if [[ "$high_count" -gt 0 ]]; then
        add_counter "vulnerabilities_detected_total" "$high_count" "$base_labels,severity=\"high\""
    fi
    if [[ "$medium_count" -gt 0 ]]; then
        add_counter "vulnerabilities_detected_total" "$medium_count" "$base_labels,severity=\"medium\""
    fi
    if [[ "$low_count" -gt 0 ]]; then
        add_counter "vulnerabilities_detected_total" "$low_count" "$base_labels,severity=\"low\""
    fi

    # Security gate blocking metrics
    if [[ "$critical_count" -gt 0 ]]; then
        increment_counter "security_gate_blocks_total" "$base_labels,severity=\"critical\""
    fi
    if [[ "$high_count" -gt 0 ]]; then
        increment_counter "security_gate_blocks_total" "$base_labels,severity=\"high\""
    fi
}

# Metric accumulation functions
increment_counter() {
    local metric_name="$1"
    local labels="$2"
    local key="${metric_name}{${labels}}"
    COUNTERS[$key]=$((${COUNTERS[$key]:-0} + 1))
}

add_counter() {
    local metric_name="$1"
    local value="$2"
    local labels="$3"
    local key="${metric_name}{${labels}}"
    COUNTERS[$key]=$((${COUNTERS[$key]:-0} + value))
}

set_gauge() {
    local metric_name="$1"
    local value="$2"
    local labels="$3"
    local key="${metric_name}{${labels}}"
    GAUGES[$key]="$value"
}

record_histogram() {
    local metric_name="$1"
    local value="$2"
    local labels="$3"
    local key="${metric_name}{${labels}}"

    # For simplicity, store histogram values as gauges
    # In production, would use proper histogram buckets
    HISTOGRAMS[$key]="$value"
}

# Generate Prometheus format metrics
generate_prometheus_metrics() {
    local output_file="$1"

    log "INFO" "Generating Prometheus format metrics..."

    # Write metrics header
    cat > "$output_file" <<EOF
# HELP vulnerability_scans_total Total number of vulnerability scans
# TYPE vulnerability_scans_total counter

# HELP vulnerability_scan_errors_total Total number of vulnerability scan errors
# TYPE vulnerability_scan_errors_total counter

# HELP vulnerability_count Current number of vulnerabilities by severity
# TYPE vulnerability_count gauge

# HELP vulnerabilities_detected_total Total number of vulnerabilities detected
# TYPE vulnerabilities_detected_total counter

# HELP security_gate_blocks_total Total number of builds blocked by security gate
# TYPE security_gate_blocks_total counter

# HELP vulnerability_scan_overrides_total Total number of emergency security overrides
# TYPE vulnerability_scan_overrides_total counter

# HELP vulnerability_scan_duration_seconds Duration of vulnerability scans in seconds
# TYPE vulnerability_scan_duration_seconds gauge

EOF

    # Write counters
    for key in "${!COUNTERS[@]}"; do
        echo "${key} ${COUNTERS[$key]}" >> "$output_file"
    done

    # Write gauges
    for key in "${!GAUGES[@]}"; do
        echo "${key} ${GAUGES[$key]}" >> "$output_file"
    done

    # Write histograms (as gauges for now)
    for key in "${!HISTOGRAMS[@]}"; do
        echo "${key} ${HISTOGRAMS[$key]}" >> "$output_file"
    done

    log "INFO" "Generated metrics file: $output_file"
}

# Ship metrics to observability platform
ship_metrics() {
    local metrics_file="$1"

    if [[ "$METRICS_DRY_RUN" == "true" ]]; then
        log "INFO" "Dry run mode - metrics not shipped"
        log "INFO" "Metrics content:"
        cat "$metrics_file" >&2
        return 0
    fi

    if [[ -z "$OBSERVABILITY_ENDPOINT" ]]; then
        log "WARN" "No observability endpoint configured - metrics not shipped"
        log "INFO" "Set OBSERVABILITY_ENDPOINT to ship metrics"
        return 0
    fi

    case "$OBSERVABILITY_PLATFORM" in
        "prometheus")
            ship_to_prometheus "$metrics_file"
            ;;
        "datadog")
            ship_to_datadog "$metrics_file"
            ;;
        "cloudwatch")
            ship_to_cloudwatch "$metrics_file"
            ;;
        *)
            log "ERROR" "Unsupported observability platform: $OBSERVABILITY_PLATFORM"
            return 1
            ;;
    esac
}

# Ship metrics to Prometheus using remote write API
ship_to_prometheus() {
    local metrics_file="$1"

    log "INFO" "Shipping metrics to Prometheus: $OBSERVABILITY_ENDPOINT"

    # Convert Prometheus format to remote write format (simplified)
    # In production, would use proper Prometheus remote write protocol

    local curl_args=()
    curl_args+=("-X" "POST")
    curl_args+=("-H" "Content-Type: application/x-protobuf")
    curl_args+=("-H" "X-Prometheus-Remote-Write-Version: 0.1.0")
    curl_args+=("--data-binary" "@$metrics_file")

    if [[ -n "$OBSERVABILITY_AUTH_TOKEN" ]]; then
        curl_args+=("-H" "Authorization: Bearer $OBSERVABILITY_AUTH_TOKEN")
    fi

    if curl "${curl_args[@]}" "$OBSERVABILITY_ENDPOINT" > /tmp/prometheus-response.log 2>&1; then
        log "INFO" "Successfully shipped metrics to Prometheus"
    else
        log "ERROR" "Failed to ship metrics to Prometheus"
        log "ERROR" "Response: $(cat /tmp/prometheus-response.log)"
        return 1
    fi
}

# Ship metrics to Datadog
ship_to_datadog() {
    local metrics_file="$1"

    log "INFO" "Shipping metrics to Datadog"
    log "WARN" "Datadog integration not yet implemented"
    return 1
}

# Ship metrics to CloudWatch
ship_to_cloudwatch() {
    local metrics_file="$1"

    log "INFO" "Shipping metrics to CloudWatch"
    log "WARN" "CloudWatch integration not yet implemented"
    return 1
}

# Main execution
main() {
    log "INFO" "Starting vulnerability metrics extraction"
    log "INFO" "Platform: $OBSERVABILITY_PLATFORM"
    log "INFO" "Endpoint: ${OBSERVABILITY_ENDPOINT:-not configured}"
    log "INFO" "Dry run: $METRICS_DRY_RUN"

    # Check if metrics are enabled
    if [[ "$METRICS_ENABLED" != "true" ]]; then
        log "INFO" "Metrics extraction disabled (METRICS_ENABLED=$METRICS_ENABLED)"
        return 0
    fi

    # Check for required tools
    if ! command -v jq >/dev/null 2>&1; then
        log "ERROR" "jq is required but not installed"
        return 1
    fi

    if ! command -v bc >/dev/null 2>&1; then
        log "ERROR" "bc is required but not installed"
        return 1
    fi

    # Process log entries
    log "INFO" "Processing log entries from: $LOG_FILE"

    local line_count=0
    local processed_count=0

    while IFS= read -r line; do
        line_count=$((line_count + 1))

        if [[ -n "$line" ]]; then
            parse_log_entry "$line"
            processed_count=$((processed_count + 1))
        fi
    done < "$LOG_FILE"

    log "INFO" "Processed $processed_count/$line_count log lines"

    # Generate metrics
    generate_prometheus_metrics "$METRICS_FILE"

    # Ship metrics
    ship_metrics "$METRICS_FILE"

    log "INFO" "Vulnerability metrics extraction completed"
}

# Run main function
main "$@"
