# Vulnerability Scanning Metrics and Observability

## Overview

This guide covers the metrics extraction and observability integration for vulnerability scanning. The system extracts operational metrics from structured logs generated during vulnerability scans and ships them to configurable observability platforms for monitoring and alerting.

## Architecture

```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│ Vulnerability   │    │ Metrics          │    │ Observability   │
│ Scanner         │───▶│ Extractor        │───▶│ Platform        │
│ (JSON Logs)     │    │ (Parse & Ship)   │    │ (Prometheus)    │
└─────────────────┘    └──────────────────┘    └─────────────────┘
```

The metrics system:
1. **Parses structured logs** from vulnerability scanning CI jobs
2. **Extracts operational metrics** (duration, counts, failures)
3. **Ships metrics** to configured observability platforms
4. **Enables alerting** on security events and operational issues

## Metrics Collected

### Scan Performance Metrics

- `vulnerability_scan_duration_seconds` - Histogram of scan execution times
- `vulnerability_scans_total` - Counter of total scans by status and result
- `vulnerability_scans_started_total` - Counter of scan initiations

### Security Metrics  

- `vulnerability_count` - Gauge of current vulnerabilities by severity
- `vulnerabilities_detected_total` - Counter of total vulnerabilities detected
- `security_gate_blocks_total` - Counter of builds blocked by security policy

### Operational Metrics

- `vulnerability_scan_errors_total` - Counter of scan failures by error type
- `vulnerability_scan_overrides_total` - Counter of emergency override usage

### Metric Labels

All metrics include these standard labels:
- `service` - Always "vulnerability-scanner"
- `environment` - CI environment (e.g., "github-actions")
- `repository` - Repository name
- `branch` - Git branch
- `status` - "success" or "failure"
- `result` - "clean", "vulnerabilities_found", "error", etc.
- `severity` - "critical", "high", "medium", "low" (for vulnerability metrics)

## Configuration

### Environment Variables

Configure metrics extraction using these environment variables in your CI:

```bash
# Observability Platform
OBSERVABILITY_PLATFORM=prometheus          # prometheus|datadog|cloudwatch
OBSERVABILITY_ENDPOINT=https://prometheus.example.com/api/v1/write
OBSERVABILITY_AUTH_TOKEN=your-auth-token

# Metrics Control
METRICS_ENABLED=true                        # Enable/disable metrics extraction
METRICS_DRY_RUN=false                      # Parse logs but don't ship metrics

# Environment Labels
CI_ENVIRONMENT=github-actions              # Environment label for metrics
GITHUB_REPOSITORY=your-org/your-repo       # Repository identifier
```

### GitHub Actions Configuration

Add these variables to your repository settings:

**Repository Variables:**
- `OBSERVABILITY_PLATFORM` - Target platform (prometheus, datadog, cloudwatch)
- `OBSERVABILITY_ENDPOINT` - Platform endpoint URL
- `METRICS_ENABLED` - Enable metrics (true/false)
- `METRICS_DRY_RUN` - Dry run mode (true/false)
- `CI_ENVIRONMENT` - Environment label

**Repository Secrets:**
- `OBSERVABILITY_AUTH_TOKEN` - Authentication token for your platform

### Platform-Specific Configuration

#### Prometheus

```bash
# Required environment variables
OBSERVABILITY_PLATFORM=prometheus
OBSERVABILITY_ENDPOINT=https://prometheus.example.com/api/v1/write
OBSERVABILITY_AUTH_TOKEN=your-bearer-token
```

**Prometheus Configuration:**
```yaml
# prometheus.yml
remote_write:
  - url: https://prometheus.example.com/api/v1/write
    headers:
      Authorization: "Bearer your-token"

# Remote read for querying
remote_read:
  - url: https://prometheus.example.com/api/v1/read
```

#### Datadog

```bash
# Required environment variables  
OBSERVABILITY_PLATFORM=datadog
OBSERVABILITY_AUTH_TOKEN=your-datadog-api-key
```

**Note:** Datadog integration is planned for future implementation.

#### CloudWatch

```bash
# Required environment variables
OBSERVABILITY_PLATFORM=cloudwatch
# AWS credentials configured via IAM roles or environment
```

**Note:** CloudWatch integration is planned for future implementation.

## Alerting

### Alert Rules

The system provides pre-configured alerting rules for common scenarios:

**Critical Alerts:**
- Critical/High vulnerabilities detected
- Multiple scan failures
- Emergency security override usage

**Warning Alerts:**
- Scan timeouts
- Performance degradation
- Medium vulnerability accumulation

**Informational Alerts:**
- Vulnerability resolution confirmation
- Scanner health monitoring

### Alert Configuration Files

- **Prometheus/Grafana:** `config/alerting/prometheus-alerts.yml`
- **Datadog:** `config/alerting/datadog-monitors.json`
- **CloudWatch:** `config/alerting/cloudwatch-alarms.cfn.yml`

### Setting Up Alerts

#### Prometheus AlertManager

1. Import alerting rules:
```bash
kubectl apply -f config/alerting/prometheus-alerts.yml
```

2. Configure AlertManager routing:
```yaml
# alertmanager.yml
route:
  group_by: ['severity', 'team']
  routes:
    - match:
        severity: critical
        team: security
      receiver: security-pagerduty
    - match:
        severity: warning
        team: platform
      receiver: platform-slack

receivers:
  - name: security-pagerduty
    pagerduty_configs:
      - service_key: your-pagerduty-key
  - name: platform-slack
    slack_configs:
      - api_url: your-slack-webhook
        channel: '#platform-alerts'
```

#### Datadog Monitors

Use the Datadog API to create monitors:
```bash
curl -X POST "https://api.datadoghq.com/api/v1/monitor" \
  -H "Content-Type: application/json" \
  -H "DD-API-KEY: your-api-key" \
  -d @config/alerting/datadog-monitors.json
```

## Dashboard Examples

### Prometheus/Grafana Dashboard

Key panels to include:

1. **Scan Success Rate**
```promql
rate(vulnerability_scans_total{status="success"}[5m]) /
rate(vulnerability_scans_total[5m])
```

2. **Current Vulnerability Counts**
```promql
sum by (severity) (vulnerability_count)
```

3. **Scan Duration Trends**
```promql
histogram_quantile(0.95,
  rate(vulnerability_scan_duration_seconds_bucket[5m])
)
```

4. **Error Rate by Type**
```promql
rate(vulnerability_scan_errors_total[5m])
```

### Sample Dashboard JSON

A complete Grafana dashboard configuration is available at:
`docs/dashboards/vulnerability-scanning-dashboard.json`

## Troubleshooting

### Common Issues

#### No Metrics Appearing

1. **Check metrics extraction logs:**
```bash
# In CI, look for metrics extraction output
grep "metrics-extractor" workflow-logs
```

2. **Verify configuration:**
```bash
# Check environment variables are set
echo $OBSERVABILITY_ENDPOINT
echo $METRICS_ENABLED
```

3. **Test locally:**
```bash
# Run metrics extraction with sample logs
export METRICS_DRY_RUN=true
./scripts/extract-vulnerability-metrics.sh sample-logs.jsonl
```

#### Authentication Failures

1. **Verify token validity:**
```bash
# Test Prometheus endpoint
curl -H "Authorization: Bearer $OBSERVABILITY_AUTH_TOKEN" \
  $OBSERVABILITY_ENDPOINT
```

2. **Check token permissions:**
- Prometheus: Requires write permissions
- Datadog: Requires metrics submission permissions
- CloudWatch: Requires PutMetricData permissions

#### Incorrect Metric Values

1. **Verify log parsing:**
```bash
# Check log format matches expected JSON structure
jq . < vulnerability-scan-logs.jsonl
```

2. **Validate metric calculations:**
```bash
# Run extraction with debug output
METRICS_DRY_RUN=true ./scripts/extract-vulnerability-metrics.sh logs.jsonl
```

### Debugging Commands

```bash
# Test metrics extraction script
export METRICS_DRY_RUN=true
export OBSERVABILITY_PLATFORM=prometheus
./scripts/extract-vulnerability-metrics.sh /path/to/logs.jsonl

# Validate generated metrics format
promtool query instant 'vulnerability_scans_total'

# Check alerting rules syntax
promtool rules verify config/alerting/prometheus-alerts.yml
```

## Security Considerations

### Data Privacy

- **No sensitive data** in metrics (source code, dependency details, etc.)
- **Correlation IDs only** for incident tracking
- **Aggregated counts** only for vulnerability metrics

### Authentication

- **Store tokens securely** in CI secrets
- **Use least-privilege** access for platform tokens
- **Rotate credentials** regularly
- **Validate TLS certificates** for all connections

### Network Security

- **HTTPS only** for metric shipping
- **Support proxy configuration** for corporate networks
- **Validate endpoints** before sending data

## Advanced Configuration

### Custom Metric Labels

Add custom labels via environment variables:
```bash
CUSTOM_LABELS='{"team":"security","cost_center":"infra"}'
```

### Metric Sampling

Control metric volume for high-frequency scans:
```bash
METRICS_SAMPLE_RATE=0.1  # Sample 10% of scan events
```

### Batch Configuration

Optimize for high-volume environments:
```bash
METRICS_BATCH_SIZE=100        # Metrics per batch
METRICS_FLUSH_INTERVAL=30s    # Batch flush interval
```

## Migration Guide

### From No Observability

1. **Enable metrics collection:**
```bash
# Set in repository variables
METRICS_ENABLED=true
METRICS_DRY_RUN=true  # Start with dry run
```

2. **Configure platform endpoint:**
```bash
# Add your observability platform details
OBSERVABILITY_PLATFORM=prometheus
OBSERVABILITY_ENDPOINT=your-endpoint
```

3. **Test and validate:**
```bash
# Check metrics generation in CI logs
# Verify no errors in extraction
```

4. **Enable shipping:**
```bash
# Disable dry run mode
METRICS_DRY_RUN=false
```

### From Basic Logging

1. **Ensure structured logging** is enabled (should be default)
2. **Add metrics extraction** step to CI workflow
3. **Configure observability platform** connection
4. **Import alerting rules** for your platform

## Support

### Documentation

- **Metrics Design:** `docs/design/metrics-extraction-design.md`
- **Alerting Rules:** `config/alerting/vulnerability-alerts.yml`
- **Security Scanning:** `docs/guides/security-scanning.md`

### Getting Help

For issues with metrics integration:

1. **Check troubleshooting section** above
2. **Review CI workflow logs** for extraction errors
3. **Validate configuration** using debug commands
4. **Test with dry run mode** to isolate issues

### Contributing

Improvements to metrics and alerting are welcome:

1. **Add new metric types** via the extraction script
2. **Contribute platform integrations** (Datadog, CloudWatch)
3. **Enhance alerting rules** for better coverage
4. **Improve dashboard templates** for visualization
